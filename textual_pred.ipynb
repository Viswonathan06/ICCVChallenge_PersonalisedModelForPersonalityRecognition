{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pickle\n",
    "import autokeras as ak\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files. \n",
    "\n",
    "# change paths here. \n",
    "\n",
    "session_train=pd.read_csv('./CSV files/session_train.csv')\n",
    "session_validation=pd.read_csv('./CSV files/session_val.csv')\n",
    "session_test=pd.read_csv('./CSV files/final_test.csv')\n",
    "\n",
    "\n",
    "train_path = './Features/TextualFeatures_csv/alltextual_withsenti_train.csv'\n",
    "val_path = './Features/TextualFeatures_csv/alltextual_withsenti_valid.csv'\n",
    "test_path = './Features/TextualFeatures_csv/alltextual_withsenti_test.csv'\n",
    "\n",
    "\n",
    "data_validation = pd.read_csv(val_path)\n",
    "data_train = pd.read_csv(train_path)\n",
    "data_test = pd.read_csv(test_path)\n",
    "\n",
    "drop_cols = ['Unnamed: 0', 'Video']\n",
    "\n",
    "data_train.columns\n",
    "data_validation.drop(drop_cols, axis = 1, inplace=True)\n",
    "data_train.drop(drop_cols, axis = 1, inplace=True)\n",
    "data_test.drop(drop_cols, axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train.index = 1267\n",
    "# data_validation.index = 1089\n",
    "\n",
    "# data_test.index = 489\n",
    "\n",
    "training_name = train_path.split('/')[3].split('_')[0]+'_'+train_path.split('/')[3].split('_')[1]+'_'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alltextual_withsenti_'"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_name\n",
    "# used later to name models and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Unnamed: 0', 'Video', 'PART.1', 'PART.2', 'GENDER', 'AGE',]\n",
    "session_train.drop(drop_cols, axis = 1, inplace=True)\n",
    "session_validation.drop(drop_cols, axis = 1, inplace=True)\n",
    "session_test.drop(drop_cols, axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(session_validation.columns)\n",
    "session_test.drop(['SESSION1', 'SESSION2', 'SESSION3', 'SESSION4' ], axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_y\n",
       "0     8\n",
       "1    56\n",
       "2    66\n",
       "3    67\n",
       "4    86"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.merge(session_train, data_train, left_on='ID_y', right_on='ID_y').drop_duplicates()\n",
    "data_validation = pd.merge(session_validation, data_validation, left_on='ID_y', right_on='ID_y').drop_duplicates()\n",
    "data_test = pd.merge(session_test, data_test, left_on='ID_y', right_on='ID_y').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_y</th>\n",
       "      <th>minute</th>\n",
       "      <th>session</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>SentiMin</th>\n",
       "      <th>SentiMax</th>\n",
       "      <th>SentiAvg</th>\n",
       "      <th>SentiStdev</th>\n",
       "      <th>Senti0-0.20</th>\n",
       "      <th>...</th>\n",
       "      <th>TurnPercent</th>\n",
       "      <th>AvgWrdPerTurn</th>\n",
       "      <th>LongestTurn</th>\n",
       "      <th>TotalWrds</th>\n",
       "      <th>STDWrdPerTurn</th>\n",
       "      <th>TimeMin</th>\n",
       "      <th>TimeMax</th>\n",
       "      <th>TimeAvg</th>\n",
       "      <th>TimeStdev</th>\n",
       "      <th>TimeTotal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>animals</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.744079</td>\n",
       "      <td>0.299785</td>\n",
       "      <td>2.269071e-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.379473</td>\n",
       "      <td>640.0</td>\n",
       "      <td>2040.0</td>\n",
       "      <td>1188.000000</td>\n",
       "      <td>457.138929</td>\n",
       "      <td>11880.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>ghost</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.497892</td>\n",
       "      <td>0.192607</td>\n",
       "      <td>1.675656e-01</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.309839</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>1152.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>17280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>lego</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>0.497892</td>\n",
       "      <td>0.497892</td>\n",
       "      <td>0.497892</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515152</td>\n",
       "      <td>4.117647</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.028534</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2720.0</td>\n",
       "      <td>1421.176471</td>\n",
       "      <td>633.513845</td>\n",
       "      <td>24160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>talk</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>0.632372</td>\n",
       "      <td>0.276262</td>\n",
       "      <td>2.370945e-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.377964</td>\n",
       "      <td>288.0</td>\n",
       "      <td>4809.0</td>\n",
       "      <td>1818.428571</td>\n",
       "      <td>1665.117401</td>\n",
       "      <td>12729.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>animals</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>0.028742</td>\n",
       "      <td>0.783591</td>\n",
       "      <td>0.400491</td>\n",
       "      <td>2.032181e-01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>2.142857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.038180</td>\n",
       "      <td>400.0</td>\n",
       "      <td>2320.0</td>\n",
       "      <td>1131.428571</td>\n",
       "      <td>493.020677</td>\n",
       "      <td>15840.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_y  minute  session gender  age  SentiMin  SentiMax  SentiAvg  \\\n",
       "0     8       0  animals      F   41  0.001008  0.744079  0.299785   \n",
       "1     8       0    ghost      F   41  0.000057  0.497892  0.192607   \n",
       "2     8       0     lego      F   41  0.497892  0.497892  0.497892   \n",
       "3     8       0     talk      F   41  0.009673  0.632372  0.276262   \n",
       "4     8       1  animals      F   41  0.028742  0.783591  0.400491   \n",
       "\n",
       "     SentiStdev  Senti0-0.20  ...  TurnPercent  AvgWrdPerTurn  LongestTurn  \\\n",
       "0  2.269071e-01          3.0  ...     0.333333       3.200000         10.0   \n",
       "1  1.675656e-01          8.0  ...     0.441176       3.800000          7.0   \n",
       "2  5.551115e-17          0.0  ...     0.515152       4.117647          9.0   \n",
       "3  2.370945e-01          3.0  ...     0.318182       4.000000          8.0   \n",
       "4  2.032181e-01          2.0  ...     0.466667       2.142857          4.0   \n",
       "\n",
       "   TotalWrds  STDWrdPerTurn  TimeMin  TimeMax      TimeAvg    TimeStdev  \\\n",
       "0       32.0       0.379473    640.0   2040.0  1188.000000   457.138929   \n",
       "1       57.0       0.309839    400.0   1720.0  1152.000000   304.000000   \n",
       "2       70.0       0.028534    520.0   2720.0  1421.176471   633.513845   \n",
       "3       28.0       0.377964    288.0   4809.0  1818.428571  1665.117401   \n",
       "4       30.0       0.038180    400.0   2320.0  1131.428571   493.020677   \n",
       "\n",
       "   TimeTotal  \n",
       "0    11880.0  \n",
       "1    17280.0  \n",
       "2    24160.0  \n",
       "3    12729.0  \n",
       "4    15840.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['OPENMINDEDNESS_Z', 'CONSCIENTIOUSNESS_Z', 'EXTRAVERSION_Z', 'AGREEABLENESS_Z', 'NEGATIVEEMOTIONALITY_Z']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_train = data_train[data_train['gender'] == 'M']\n",
    "F_train = data_train[data_train['gender'] == 'F']\n",
    "\n",
    "M_val = data_validation[data_validation['gender'] == 'M']\n",
    "F_val = data_validation[data_validation['gender'] == 'F']\n",
    "\n",
    "M_test = data_test[data_test['gender'] == 'M']\n",
    "F_test = data_test[data_test['gender'] == 'F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = data_train[data_train['age'] <= 30]\n",
    "O_train = data_train[data_train['age'] > 30]\n",
    "\n",
    "Y_val = data_validation[data_validation['age'] <= 30]\n",
    "O_val = data_validation[data_validation['age'] > 30]\n",
    "\n",
    "Y_test = data_test[data_test['age'] <= 30]\n",
    "O_test = data_test[data_test['age'] > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID_y', 'OPENMINDEDNESS_Z', 'CONSCIENTIOUSNESS_Z', 'EXTRAVERSION_Z',\n",
       "       'AGREEABLENESS_Z', 'NEGATIVEEMOTIONALITY_Z', 'minute', 'session',\n",
       "       'gender', 'age', 'SentiMin', 'SentiMax', 'SentiAvg', 'SentiStdev',\n",
       "       'Senti0-0.20', 'Senti0.21-0.40', 'Senti0.41-0.60', 'Senti0.61-0.80',\n",
       "       'Senti0.81-1.00', 'SentiTotal', 'TraitMin', 'TraitMax', 'TraitAvg',\n",
       "       'TraitStdev', 'TraitTotal', 'TurnPercent', 'AvgWrdPerTurn',\n",
       "       'LongestTurn', 'TotalWrds', 'STDWrdPerTurn', 'TimeMin', 'TimeMax',\n",
       "       'TimeAvg', 'TimeStdev', 'TimeTotal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 35)\n",
      "(870, 35)\n",
      "(870, 35)\n"
     ]
    }
   ],
   "source": [
    "print(data_train[data_train['age'] <= 30].shape)\n",
    "print(data_validation[data_validation['age'] <= 30].shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_train = M_train.append(M_val)\n",
    "F_train = F_train.append(F_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.append(Y_val)\n",
    "O_train = O_train.append(O_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1547, 35)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = data_train.append(data_validation)\n",
    "df_validation = data_validation\n",
    "df_test = data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined \n",
    "train_O = df_train.pop(labels[0]).to_numpy()\n",
    "train_C = df_train.pop(labels[1]).to_numpy()\n",
    "train_E = df_train.pop(labels[2]).to_numpy()\n",
    "train_A = df_train.pop(labels[3]).to_numpy()\n",
    "train_N = df_train.pop(labels[4]).to_numpy()\n",
    "\n",
    "val_O = df_validation.pop(labels[0]).to_numpy()\n",
    "val_C = df_validation.pop(labels[1]).to_numpy()\n",
    "val_E = df_validation.pop(labels[2]).to_numpy()\n",
    "val_A = df_validation.pop(labels[3]).to_numpy()\n",
    "val_N = df_validation.pop(labels[4]).to_numpy()\n",
    "\n",
    "# male train OCEAN \n",
    "M_train_O = M_train.pop(labels[0]).to_numpy()\n",
    "M_train_C = M_train.pop(labels[1]).to_numpy()\n",
    "M_train_E = M_train.pop(labels[2]).to_numpy()\n",
    "M_train_A = M_train.pop(labels[3]).to_numpy()\n",
    "M_train_N= M_train.pop(labels[4]).to_numpy()\n",
    "\n",
    "# female train OCEAN\n",
    "F_train_O = F_train.pop(labels[0]).to_numpy()\n",
    "F_train_C = F_train.pop(labels[1]).to_numpy()\n",
    "F_train_E = F_train.pop(labels[2]).to_numpy()\n",
    "F_train_A = F_train.pop(labels[3]).to_numpy()\n",
    "F_train_N= F_train.pop(labels[4]).to_numpy()\n",
    "\n",
    "# male validation OCEAN\n",
    "\n",
    "M_val_O = M_val.pop(labels[0]).to_numpy()\n",
    "M_val_C = M_val.pop(labels[1]).to_numpy()\n",
    "M_val_E = M_val.pop(labels[2]).to_numpy()\n",
    "M_val_A = M_val.pop(labels[3]).to_numpy()\n",
    "M_val_N = M_val.pop(labels[4]).to_numpy()\n",
    "\n",
    "# female validation OCEAN\n",
    "\n",
    "F_val_O = F_val.pop(labels[0]).to_numpy()\n",
    "F_val_C = F_val.pop(labels[1]).to_numpy()\n",
    "F_val_E = F_val.pop(labels[2]).to_numpy()\n",
    "F_val_A = F_val.pop(labels[3]).to_numpy()\n",
    "F_val_N = F_val.pop(labels[4]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# male train OCEAN \n",
    "Y_train_O = Y_train.pop(labels[0]).to_numpy()\n",
    "Y_train_C = Y_train.pop(labels[1]).to_numpy()\n",
    "Y_train_E = Y_train.pop(labels[2]).to_numpy()\n",
    "Y_train_A = Y_train.pop(labels[3]).to_numpy()\n",
    "Y_train_N=  Y_train.pop(labels[4]).to_numpy()\n",
    "\n",
    "# female train OCEAN\n",
    "O_train_O = O_train.pop(labels[0]).to_numpy()\n",
    "O_train_C = O_train.pop(labels[1]).to_numpy()\n",
    "O_train_E = O_train.pop(labels[2]).to_numpy()\n",
    "O_train_A = O_train.pop(labels[3]).to_numpy()\n",
    "O_train_N=  O_train.pop(labels[4]).to_numpy()\n",
    "\n",
    "# male validation OCEAN\n",
    "\n",
    "Y_val_O = Y_val.pop(labels[0]).to_numpy()\n",
    "Y_val_C = Y_val.pop(labels[1]).to_numpy()\n",
    "Y_val_E = Y_val.pop(labels[2]).to_numpy()\n",
    "Y_val_A = Y_val.pop(labels[3]).to_numpy()\n",
    "Y_val_N = Y_val.pop(labels[4]).to_numpy()\n",
    "\n",
    "# female validation OCEAN\n",
    "\n",
    "O_val_O = O_val.pop(labels[0]).to_numpy()\n",
    "O_val_C = O_val.pop(labels[1]).to_numpy()\n",
    "O_val_E = O_val.pop(labels[2]).to_numpy()\n",
    "O_val_A = O_val.pop(labels[3]).to_numpy()\n",
    "O_val_N = O_val.pop(labels[4]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = [ 'ID_y', 'minute']\n",
    "drop_cols = []\n",
    "\n",
    "train_data = df_train[data_cols]\n",
    "val_data   = df_validation[data_cols]\n",
    "test_data  = df_test[data_cols]\n",
    "\n",
    "Y_train_data = Y_train[data_cols]\n",
    "Y_val_data   = Y_val[data_cols]\n",
    "Y_test_data  = Y_test[data_cols]\n",
    "\n",
    "O_train_data = O_train[data_cols]\n",
    "O_val_data   = O_val[data_cols]\n",
    "O_test_data  = O_test[data_cols]\n",
    "\n",
    "M_train_data = M_train[data_cols]\n",
    "F_train_data = F_train[data_cols]\n",
    "M_val_data = M_val[data_cols]\n",
    "F_val_data = F_val[data_cols]\n",
    "M_test_data = M_test[data_cols]\n",
    "F_test_data = F_test[data_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,   48,   49,\n",
       "            ...\n",
       "            2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160],\n",
       "           dtype='int64', length=1547)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cols = ['ID_y','minute', 'session', 'gender', 'age']\n",
    "# combined\n",
    "train_com = df_train.drop(data_cols+drop_cols, axis = 1)\n",
    "val_com   = df_validation.drop(data_cols+drop_cols, axis = 1)\n",
    "test_com  = df_test.drop(data_cols+drop_cols, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# Age\n",
    "Y_train = Y_train.drop(data_cols+drop_cols, axis = 1)\n",
    "Y_val   = Y_val.drop(data_cols+drop_cols, axis = 1)\n",
    "Y_test  = Y_test.drop(data_cols+drop_cols, axis = 1)\n",
    "\n",
    "O_train = O_train.drop(data_cols+drop_cols, axis = 1)\n",
    "O_val   = O_val.drop(data_cols+drop_cols, axis = 1)\n",
    "O_test  = O_test.drop(data_cols+drop_cols, axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# Gender\n",
    "M_train = M_train.drop(data_cols+drop_cols, axis = 1)\n",
    "M_val = M_val.drop(data_cols+drop_cols, axis = 1)\n",
    "M_test = M_test.drop(data_cols+drop_cols, axis = 1)\n",
    "\n",
    "F_train = F_train.drop(data_cols+drop_cols, axis = 1)\n",
    "F_val = F_val.drop(data_cols+drop_cols, axis = 1)\n",
    "F_test = F_test.drop(data_cols+drop_cols, axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comvined\n",
    "train_data.reset_index(drop = True, inplace = True)\n",
    "val_data.reset_index(drop = True, inplace = True)\n",
    "test_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "# Age\n",
    "\n",
    "Y_train.reset_index(drop=True, inplace=True)\n",
    "Y_train_data.reset_index(drop=True, inplace=True)\n",
    "Y_test.reset_index(drop=True, inplace=True)\n",
    "Y_test_data.reset_index(drop = True, inplace = True)\n",
    "Y_val.reset_index(drop=True, inplace=True)\n",
    "Y_val_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "O_train.reset_index(drop=True, inplace=True)\n",
    "O_train_data.reset_index(drop=True, inplace=True)\n",
    "O_val.reset_index(drop=True, inplace=True)\n",
    "O_val_data.reset_index(drop=True, inplace=True)\n",
    "O_test.reset_index(drop=True, inplace=True)\n",
    "O_test_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# Gender\n",
    "M_train.reset_index(drop=True, inplace=True)\n",
    "M_train_data.reset_index(drop=True, inplace=True)\n",
    "M_test.reset_index(drop=True, inplace=True)\n",
    "M_test_data.reset_index(drop = True, inplace = True)\n",
    "M_val.reset_index(drop=True, inplace=True)\n",
    "M_val_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "F_train.reset_index(drop=True, inplace=True)\n",
    "F_train_data.reset_index(drop=True, inplace=True)\n",
    "F_val.reset_index(drop=True, inplace=True)\n",
    "F_val_data.reset_index(drop=True, inplace=True)\n",
    "F_test.reset_index(drop=True, inplace=True)\n",
    "F_test_data.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356, 2)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2356,)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OCEAN_models = ['Model_O', 'Model_C', 'Model_E', 'Model_A', 'Model_N']\n",
    "# Combined\n",
    "train_com_np = np.array(train_com)\n",
    "val_com_np = np.array(val_com)\n",
    "test_com_np = np.array(test_com)\n",
    "\n",
    "# Age\n",
    "Y_train_np = np.array(Y_train)\n",
    "Y_test_np  = np.array(Y_test)\n",
    "Y_val_np   = np.array(Y_val)\n",
    "\n",
    "\n",
    "O_train_np = np.array(O_train)\n",
    "O_val_np   = np.array(O_val)\n",
    "O_test_np  = np.array(O_test)\n",
    "\n",
    "# GEnder\n",
    "M_train_np = np.array(M_train)\n",
    "M_test_np  = np.array(M_test)\n",
    "M_val_np   = np.array(M_val)\n",
    "\n",
    "\n",
    "F_train_np = np.array(F_train)\n",
    "F_val_np   = np.array(F_val)\n",
    "F_test_np  = np.array(F_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined\n",
    "comb_O_train_set = tf.data.Dataset.from_tensor_slices((train_com_np, train_O))\n",
    "comb_C_train_set = tf.data.Dataset.from_tensor_slices((train_com_np, train_C))\n",
    "comb_E_train_set = tf.data.Dataset.from_tensor_slices((train_com_np, train_E))\n",
    "comb_A_train_set = tf.data.Dataset.from_tensor_slices((train_com_np, train_A))\n",
    "comb_N_train_set = tf.data.Dataset.from_tensor_slices((train_com_np, train_N))\n",
    "\n",
    "comb_O_validation_set = tf.data.Dataset.from_tensor_slices((val_com_np, val_O))\n",
    "comb_C_validation_set = tf.data.Dataset.from_tensor_slices((val_com_np, val_C))\n",
    "comb_E_validation_set = tf.data.Dataset.from_tensor_slices((val_com_np, val_E))\n",
    "comb_A_validation_set = tf.data.Dataset.from_tensor_slices((val_com_np, val_A))\n",
    "comb_N_validation_set = tf.data.Dataset.from_tensor_slices((val_com_np, val_N))\n",
    "\n",
    "\n",
    "# Age\n",
    "\n",
    "youngO_train_set      = tf.data.Dataset.from_tensor_slices((Y_train_np, Y_train_O))\n",
    "youngC_train_set      = tf.data.Dataset.from_tensor_slices((Y_train_np, Y_train_C))\n",
    "youngE_train_set      = tf.data.Dataset.from_tensor_slices((Y_train_np, Y_train_E))\n",
    "youngA_train_set      = tf.data.Dataset.from_tensor_slices((Y_train_np, Y_train_A))\n",
    "youngN_train_set      = tf.data.Dataset.from_tensor_slices((Y_train_np, Y_train_N))\n",
    "youngO_validation_set = tf.data.Dataset.from_tensor_slices((Y_val_np, Y_val_O))\n",
    "youngC_validation_set = tf.data.Dataset.from_tensor_slices((Y_val_np, Y_val_C))\n",
    "youngE_validation_set = tf.data.Dataset.from_tensor_slices((Y_val_np, Y_val_E))\n",
    "youngA_validation_set = tf.data.Dataset.from_tensor_slices((Y_val_np, Y_val_A))\n",
    "youngN_validation_set = tf.data.Dataset.from_tensor_slices((Y_val_np, Y_val_N))\n",
    "\n",
    "oldO_validation_set = tf.data.Dataset.from_tensor_slices((O_val_np, O_val_O))\n",
    "oldC_validation_set = tf.data.Dataset.from_tensor_slices((O_val_np, O_val_C))\n",
    "oldE_validation_set = tf.data.Dataset.from_tensor_slices((O_val_np, O_val_E))\n",
    "oldA_validation_set = tf.data.Dataset.from_tensor_slices((O_val_np, O_val_A))\n",
    "oldN_validation_set = tf.data.Dataset.from_tensor_slices((O_val_np, O_val_N))\n",
    "oldO_train_set      = tf.data.Dataset.from_tensor_slices((O_train_np, O_train_O))\n",
    "oldC_train_set      = tf.data.Dataset.from_tensor_slices((O_train_np, O_train_C))\n",
    "oldE_train_set      = tf.data.Dataset.from_tensor_slices((O_train_np, O_train_E))\n",
    "oldA_train_set      = tf.data.Dataset.from_tensor_slices((O_train_np, O_train_A))\n",
    "oldN_train_set      = tf.data.Dataset.from_tensor_slices((O_train_np, O_train_N))\n",
    "\n",
    "\n",
    "# Gender\n",
    "maleO_train_set = tf.data.Dataset.from_tensor_slices((M_train_np, M_train_O))\n",
    "maleC_train_set = tf.data.Dataset.from_tensor_slices((M_train_np, M_train_C))\n",
    "maleE_train_set = tf.data.Dataset.from_tensor_slices((M_train_np, M_train_E))\n",
    "maleA_train_set = tf.data.Dataset.from_tensor_slices((M_train_np, M_train_A))\n",
    "maleN_train_set = tf.data.Dataset.from_tensor_slices((M_train_np, M_train_N))\n",
    "\n",
    "femaleO_train_set = tf.data.Dataset.from_tensor_slices((F_train_np, F_train_O))\n",
    "femaleC_train_set = tf.data.Dataset.from_tensor_slices((F_train_np, F_train_C))\n",
    "femaleE_train_set = tf.data.Dataset.from_tensor_slices((F_train_np, F_train_E))\n",
    "femaleA_train_set = tf.data.Dataset.from_tensor_slices((F_train_np, F_train_A))\n",
    "femaleN_train_set = tf.data.Dataset.from_tensor_slices((F_train_np, F_train_N))\n",
    "\n",
    "maleO_validation_set = tf.data.Dataset.from_tensor_slices((M_val_np, M_val_O))\n",
    "maleC_validation_set = tf.data.Dataset.from_tensor_slices((M_val_np, M_val_C))\n",
    "maleE_validation_set = tf.data.Dataset.from_tensor_slices((M_val_np, M_val_E))\n",
    "maleA_validation_set = tf.data.Dataset.from_tensor_slices((M_val_np, M_val_A))\n",
    "maleN_validation_set = tf.data.Dataset.from_tensor_slices((M_val_np, M_val_N))\n",
    "\n",
    "femaleO_validation_set = tf.data.Dataset.from_tensor_slices((F_val_np, F_val_O))\n",
    "femaleC_validation_set = tf.data.Dataset.from_tensor_slices((F_val_np, F_val_C))\n",
    "femaleE_validation_set = tf.data.Dataset.from_tensor_slices((F_val_np, F_val_E))\n",
    "femaleA_validation_set = tf.data.Dataset.from_tensor_slices((F_val_np, F_val_A))\n",
    "femaleN_validation_set = tf.data.Dataset.from_tensor_slices((F_val_np, F_val_N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined\n",
    "comb_train_set = [comb_O_train_set, \n",
    "                  comb_C_train_set, \n",
    "                  comb_E_train_set, \n",
    "                  comb_A_train_set, \n",
    "                  comb_N_train_set]\n",
    "\n",
    "comb_validation_set = [comb_O_validation_set, \n",
    "                       comb_C_validation_set, \n",
    "                       comb_E_validation_set, \n",
    "                       comb_A_validation_set, \n",
    "                       comb_N_validation_set]\n",
    "\n",
    "# Age\n",
    "young_train_set =     [youngO_train_set, \n",
    "                       youngC_train_set, \n",
    "                       youngE_train_set, \n",
    "                       youngA_train_set, \n",
    "                       youngN_train_set]\n",
    "young_validation_set =[youngO_validation_set, \n",
    "                       youngC_validation_set, \n",
    "                       youngE_validation_set, \n",
    "                       youngA_validation_set, \n",
    "                       youngN_validation_set]\n",
    "\n",
    "old_train_set =         [oldO_train_set, \n",
    "                         oldC_train_set, \n",
    "                         oldE_train_set,\n",
    "                         oldA_train_set,\n",
    "                         oldN_train_set]\n",
    "old_validation_set =    [oldO_validation_set,\n",
    "                         oldC_validation_set,\n",
    "                         oldE_validation_set,\n",
    "                         oldA_validation_set,\n",
    "                         oldN_validation_set]\n",
    "\n",
    "# Gender\n",
    "male_train_set =      [maleO_train_set, \n",
    "                       maleC_train_set, \n",
    "                       maleE_train_set, \n",
    "                       maleA_train_set, \n",
    "                       maleN_train_set]\n",
    "male_validation_set = [maleO_validation_set, \n",
    "                       maleC_validation_set, \n",
    "                       maleE_validation_set, \n",
    "                       maleA_validation_set, \n",
    "                       maleN_validation_set]\n",
    "\n",
    "female_train_set =      [femaleO_train_set, \n",
    "                         femaleC_train_set, \n",
    "                         femaleE_train_set,\n",
    "                         femaleA_train_set,\n",
    "                         femaleN_train_set]\n",
    "female_validation_set = [femaleO_validation_set,\n",
    "                         femaleC_validation_set,\n",
    "                         femaleE_validation_set,\n",
    "                         femaleA_validation_set,\n",
    "                         femaleN_validation_set]\n",
    "\n",
    "model_names = ['Model_O','Model_C','Model_E','Model_A','Model_N']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alltextual_withsenti_'"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "285\n",
      "(285, 1)\n",
      "285\n",
      "(285, 1)\n",
      "285\n",
      "(285, 1)\n",
      "285\n",
      "(285, 1)\n",
      "285\n",
      "(285, 1)\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "204\n",
      "Index(['ID_y', 'minute', 0, 0, 0, 0, 0], dtype='object')\n",
      "Prediction over\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Change this according to the path of male and female\n",
    "male_path = './Textual Models/'+training_name+'/Gender/Male/'\n",
    "female_path = './Textual Models/'+training_name+'/Gender/Female/'\n",
    "\n",
    "young_path = './Textual Models/'+training_name+'/Age/Young/'\n",
    "old_path = './Textual Models/'+training_name+'/Age/Old/'\n",
    "\n",
    "separation = male_path.split('/')[3]\n",
    "print(separation)\n",
    "\n",
    "# change this to whatever you have named the folders where each model is inside male and female\n",
    "OCEAN_models = ['Model_O', 'Model_C', 'Model_E', 'Model_A', 'Model_N']\n",
    "# Make sure they have similar names\n",
    "for mod in OCEAN_models:\n",
    "    \n",
    "    model = tf.keras.models.load_model(male_path+mod)\n",
    "    prediction = model.predict(M_test_np)\n",
    "    # print((prediction))\n",
    "    print(len(prediction))\n",
    "    prediction = np.array(prediction)\n",
    "    print(prediction.shape)\n",
    "    M_test_data = pd.concat([M_test_data, pd.DataFrame(prediction)], axis=1)\n",
    "# Here F_test_data is only the ID and minute columns of the test data you're passing in, which we are merging the \n",
    "# predictions with. \n",
    "# Make sure you change it to whatever your dataframe is.\n",
    "\n",
    "# F_test_data.to_csv(\"./Results/fb_pred.csv\")\n",
    "\n",
    "\"\"\"# Making predictions based on female models for OCEAN individually\"\"\"\n",
    "\n",
    "for mod in OCEAN_models:\n",
    "    model = tf.keras.models.load_model(female_path+mod)\n",
    "    prediction = model.predict(F_test_np)\n",
    "    print(len(prediction))\n",
    "    prediction = np.array(prediction)\n",
    "    F_test_data = pd.concat([F_test_data, pd.DataFrame(prediction)], axis=1)\n",
    "\n",
    "total_test_data = F_test_data.append(M_test_data)\n",
    "print(total_test_data.columns)\n",
    "total_test_data=total_test_data.sort_values(by=['ID_y'])\n",
    "total_test_data.to_csv(\"./Results/\"+training_name+\"pred_\"+separation+\"_minute.csv\")\n",
    "print(\"Prediction over\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_y</th>\n",
       "      <th>minute</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.212068</td>\n",
       "      <td>0.270076</td>\n",
       "      <td>-0.282435</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>-0.217193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1.094202</td>\n",
       "      <td>0.257162</td>\n",
       "      <td>-0.086997</td>\n",
       "      <td>0.276457</td>\n",
       "      <td>-0.045503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.061600</td>\n",
       "      <td>0.047626</td>\n",
       "      <td>-0.089956</td>\n",
       "      <td>-0.182099</td>\n",
       "      <td>-0.074689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.045719</td>\n",
       "      <td>0.055427</td>\n",
       "      <td>-0.183186</td>\n",
       "      <td>-0.120476</td>\n",
       "      <td>0.009236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.779887</td>\n",
       "      <td>0.212846</td>\n",
       "      <td>0.021240</td>\n",
       "      <td>0.028920</td>\n",
       "      <td>-0.147573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_y  minute         0         0         0         0         0\n",
       "0      8       0  0.212068  0.270076 -0.282435  0.015398 -0.217193\n",
       "22     8       6  1.094202  0.257162 -0.086997  0.276457 -0.045503\n",
       "21     8       5 -0.061600  0.047626 -0.089956 -0.182099 -0.074689\n",
       "20     8       5 -0.045719  0.055427 -0.183186 -0.120476  0.009236\n",
       "19     8       4  0.779887  0.212846  0.021240  0.028920 -0.147573"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test_data.drop(['minute'], axis = 1, inplace=True)\n",
    "df_fb = total_test_data.reset_index(drop= True)\n",
    "\n",
    "mean_df_fb = df_fb.groupby(['ID_y'], as_index=False).mean()\n",
    "mean_df_fb.columns = [0, 1, 2, 3, 4, 5]\n",
    "mean_df_fb.to_csv(\"./Results/\"+training_name+\"pred_\"+separation+\"_mean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
